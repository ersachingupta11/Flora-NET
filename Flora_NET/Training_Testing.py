# -*- coding: utf-8 -*-
"""Untitled26.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L6FA7tjzHbMW28CMKX-Ms8IZl1oTnuII

**Initialization**
"""

# define loss criterion, epochs and learning rate
criterion = nn.CrossEntropyLoss()
epochs = 100
lr = 0.001

"""**Training and Testing**"""

def train_model(model, loss_criterion, epochs, learning_rate):

  # Define the loss function
  criterion = loss_criterion

  # Define the optimizer
  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

  # Training loop
  num_epochs = epochs

  # Lists to store metrics for plotting
  train_loss_history = []
  val_loss_history = []
  train_acc_history = []
  val_acc_history = []

  for epoch in range(num_epochs):
      model.train()  # Set the model to training mode
      train_loss = 0.0
      correct_train = 0
      total_train = 0

      # Training phase
      for images, labels in train_loader:
          # Forward pass
          outputs = model(images)
          loss = criterion(outputs, labels)

          # Backward pass and optimization
          optimizer.zero_grad()
          loss.backward()
          optimizer.step()

          # Compute training accuracy
          _, predicted = torch.max(outputs, 1)
          total_train += labels.size(0)
          correct_train += (predicted == labels).sum().item()

          train_loss += loss.item()

      # Calculate average training loss and accuracy
      train_loss = train_loss / len(train_loader)
      train_accuracy = 100 * correct_train / total_train
      train_loss_history.append(train_loss)
      train_acc_history.append(train_accuracy)

      # Validation phase
      model.eval()  # Set the model to evaluation mode
      val_loss = 0.0
      correct_val = 0
      total_val = 0

      with torch.no_grad():
          for images, labels in val_loader:
              outputs = model(images)
              loss = criterion(outputs, labels)

              # Compute validation accuracy
              _, predicted = torch.max(outputs, 1)
              total_val += labels.size(0)
              correct_val += (predicted == labels).sum().item()

              val_loss += loss.item()

      # Calculate average validation loss and accuracy
      val_loss = val_loss / len(val_loader)
      val_accuracy = 100 * correct_val / total_val
      val_loss_history.append(val_loss)
      val_acc_history.append(val_accuracy)

      print(f"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%")

  return [train_loss_history, val_loss_history, train_acc_history, val_acc_history]

"""**Training and Testing Curves**"""

def plot_graphs(train_loss_history, val_loss_history, train_acc_history, val_acc_history):

  # Plotting the training and validation loss
  plt.plot(train_loss_history, label='Train Loss')
  plt.plot(val_loss_history, label='Validation Loss')
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.title('Training and Validation Loss')
  plt.legend()
  plt.show()

  # Plotting the training and validation accuracy
  plt.plot(train_acc_history, label='Train Accuracy')
  plt.plot(val_acc_history, label='Validation Accuracy')
  plt.xlabel('Epoch')
  plt.ylabel('Accuracy (%)')
  plt.title('Training and Validation Accuracy')
  plt.legend()
  plt.show()

"""**Testing Accuracy**"""

def test_model(model, model_name):
  model.eval()  # Set the model to evaluation mode
  correct = 0
  total = 0

  with torch.no_grad():
      for images, labels in test_loader:
          outputs = model(images)
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()

  print(f"Test Accuracy for {model_name}: {(100 * correct / total):.2f}%")

"""**Function Calling**"""

# Training
metrics = train_model(Flora_NET, criterion, epochs, lr)
train_loss_history = metrics[0]
val_loss_history = metrics[1]
train_acc_history = metrics[2]
val_acc_history = metrics[3]
# plot the model graphs
plot_graphs(train_loss_history, val_loss_history, train_acc_history, val_acc_history)

"""**Testing the Flora_NET model**"""

# test model
test_model(Flora_NET, "Flora-NET Model")
import copy

Flora_NET.eval()  # Set the model to evaluation mode

# Define lists to store the predicted labels, actual labels, and images
predicted_labels = []
actual_labels = []
images_to_display = []

with torch.no_grad():
    correct = 0
    total = 0

    for images, labels in test_loader:  # Assuming you have a separate test dataloader
        images_to_display.extend(images)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        # Convert the predicted and actual labels to a list
        predicted_labels.extend(predicted.tolist())
        actual_labels.extend(labels.tolist())

        # Store the images


        # Count the number of correct predictions
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

# Print the results
print("Number of correct predictions:", correct, "out of", total)
print()

# Display the images along with their predicted and actual labels
for i in range(len(predicted_labels)):
    print("Image:", i+1)
    print("Predicted Label:", class_names[predicted_labels[i]])
    print("Actual Label:", class_names[actual_labels[i]])
    print("Correct Prediction:", "Yes" if predicted_labels[i] == actual_labels[i] else "No")
    # Display the image
    img = copy.deepcopy(images_to_display[i])
    # plt.imshow(transforms.ToPILImage()(img))
    img = img / 2 + 0.5  # Unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    # plt.imshow(images_to_display[i].permute(1, 2, 0))
    plt.show()
    print()